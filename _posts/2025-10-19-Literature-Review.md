---
layout: post
title: Literature review on using Deel Learning to identify misinformation on social media
subtitle: Unit 2
categories: Literature Review
tags: [literature, review]
---

My next assignment was to write a literature review on one of the topics of choice. I chose the topic of usage of Deep Learning for misinformation detection on social media.

## Literature review: Deep Learning tool to detect misinformation on social media. 

The literature review is about evolving technologies used to identify misinformation on social media platforms. There are different ways to identify false information, and the terms are constantly evolving. Islam  (Islam et al., 2020) elaborated that “there are numerous terms related to misinformation including fake news, rumours, spam, and disinformation”. While different kind of fake news can lead to dangerous outcomes, I think it is important to look at the intention behind. Nipa Akter (Akter et al., 2025) classifies following terms based on intention: satire/parody, rumours, conspiracy theories, scams and hoaxes, clickbait, misinformation and disinformation, stating that the later has malicious intentions. In all the papers I have read on the topic, authors agree on the urgent need to identify false information and hopefully prevent it from spreading. (Akter et al., 2025) in their paper specifically go beyond past and look at the forecasting the effect of misinformation. The reason for this consensus among researchers in the field is that fact that the speed with which fake news tends to spread is very fast and the consequences are dire and can cause harm to the humanity. The example I can never get over is the hate amplified by Facebook against Rohingya Muslims which led to violence in Myanmar (Wiessmann, 2024). The problem with misinformation is that it is difficult to distinguish and users of social media platforms tend to trust it and spread it (Akter et al., 2025). Example with Rohingya is just one of thousand instances I can think of. Among others the common case in India when the news is spread using WhatsApp with fake pictures of culprits and that leads to violence. 
Along with methods used to identify misinformation on social media evolve the attacks of culprits. Lately such phenomena as using like deep fakes and multimodality made the complex task even more challenging (Akter et al., 2025).  The variety of modalities adds to the task complexity along with the speed of change. 
In this literature review I would like to put exiting research in historical context since the technology is evolving rapidly and most of the articles from 2020 are not that relevant anymore. The objective is to analyse the strengths and weaknesses of different approaches starting with CNN, RNN, LSTM, GNN, and transformer-based models like BERT, RoBERTa, GPT-3, as well as hybrid architecture. I believe that those articles that do not utilize the power of transformers are outdated, and I tend to agree with Akter (Akter et al., 2025) that the future of this research lies in anticipation of fake news spread and its timely prevention. Looking forward is very important considering that the problem of classification and identification of the fake news have been successfully tackled by now as it will be clear from this literature review. 
I started exploring the topic looking at the literature maximum five years old but quickly realised that the major change came with introduction of transformers and looked at more recent papers. All the papers I have included employ Deep Learning for text analytics using various approaches to check the “truth”.
A history of NLP pretraining started with word2vec back in 2013 (Mikolov et al., 2013), then came out GloVE - Global Vectors for Word Representation (Pennington et al., 2014) followed by Contextualized Word Vectors COVE (McCann et al., 2017). Afterwards followed the revolutionary paper in the field introducing transformer by Vaswani and colleagues from Google Brain at the conference in 2017 (Vaswani et al., 2017). The power of transformers is in parallelization of input – it is something that sequential models struggles with before. Long sequences are a challenge since each step depends on the previous step and its input (Bahdanau et al., 2016). Transformer based models like BERT and GPT are more powerful and outperform sequential models. There are autoregressive models that belong to GPT family, and they correspond to the decoder part of the original transformer model. The autoencoder models of BERT family correspond to encoder part of the transformer model and are pre-trained on Masked Language Modelling tasks – so they are trained to guess missing word using self-attention (Liu et al., 2019). The other two types are Sequel to Sequel models and multi-modal models like OpenAI models (Alammar, 2021). 
Some of the articles reviewed use more simple language models like RNN, CNN, LSTM (Islam et al., 2020), (Nair et al., 2024) while some use transformers (Twum, 2025) and others the combination of both . There are many factors that help to identify “fake” news (Nair et al., 2024). One of them is the spread pattern (Vosoughi et al., 2018). As Vosoughi and colleagues demonstrated, false news spreads “farther, faster, deeper, and more broadly” than true news on Twitter, a finding that has been replicated across multiple platforms. Another one is strengths of emotions evoked – factual news does not trigger such strong emotions as misinformation. 
While the complexity might be high and included like in Akter where authors analysed user behaviour and news propagation along with the content, their model based on combination of AI and NLP showed more poor results in comparison with text only input used by Patel and Sutrakar (Patel & Sutrakar, 2025). The later authors used Advanced Text Analytics (ATA) GNN to capture detailed and “intricate relationships in the text” for better interpretation and used  joint word and document clustering to build graphs (Patel & Sutrakar, 2025). Patel and Sutrakar only used source tweets for their graph model which is an excellent practical approach when dissemination of information is not known yet the twitter posts can be identify as misinformation. I think the future of this topic could lie in the forecasting which tweet/news can be dangerous and become viral. Patel’s and Sutrakar’s model demonstrated excellent results with accuracy above 90% as well as importance of topic modelling. Although the spread of the information pattern is one of the factors that help to identify the “fakeness” of the information (Nair et al., 2024) – if it can be inferred just from the text itself there is no need for complexity. The simplicity and straightforwardness of the approach is both strength and limitation. In the absence of comments, retweets and propagation patterns the false information can be identified.  While it is close to impossible to compare different in approach research designs, I can use accuracy metrics to draw conclusions and the accuracy of Patel’s & Sutrakr’s model reached 90%. Authors demonstrated that high performing GNN could be built however the results were good on curated datasets Twitter15, Twitter16, PHEME and could be not as effective on noisy real data.  
Another unique approach which I value a lot was created by Nair and colleagues (Nair et al., 2024). To check the “truthfulness” of the information all tweets we reduced to Subject-Predicate-Object (SPO)s.  SPOs were used as triplets for content along with positive/negative sentiment, frequency of retweets and likes, and LDA to create a knowledge graph to check facts. RNN, GRU, LSTM and BERT were used to identify patterns however BERT was only used in combination with other algorithms. While the accuracy was far from excellent the authors created a clear conceptual approach to identifying key factors that characterise misinformation (Nair et al., 2024). Perhaps using full power of transformer would enhance the results of their study while using hybrid approach hindered the results. 
Along with Nair et al, Moorthy et al also utilized hybrid approach combining BERT for text feature extraction and GNN to capture propagation context and got fusion results which outperform individual BERT and GNN only approaches. Moorthy (Rama Moorthy et al., 2025) and colleagues took in consideration the way false information spreads among users on social media and utilised attention-based mechanism to consider signals at times from content and at times from context to identify misinformation. Adding textual context analysis enhances the only GNN model by Patel (Patel & Sutrakar, 2025) and reaches the accuracy of 99%. I could think of this model almost overfitting. The only disadvantage I see is that the study used FakeNewsNet dataset instead of real social platform. 
Now that I have considered ML Models and hybrid architectures, to balance the review I am including purely transformer based approached utilized by Azizah and colleagues (Azizah et al., 2023). Azizah and colleagues compare performance of four transformer-based models. I believe that BERT shines on misinformation identification tasks since it is built to identify contextual embeddings which means it considers whole sentence to identify the meaning of the word and that is where it outperforms Word2Vec which returns only literal meaning. 
By comparing transformer-based models like BERT, ALBERT, and RoBERTa for fake news identification in Bahasa Indonesia, Azizah et al. (2023) made a significant contribution and demonstrated that even lightweight architectures like ALBERT functions well in environments with limited resources. Azizah method only worked with textual data and performed mediocre when compared against English benchmarks, emphasizing the difficulties in translating models between languages. Nair et al. (2024) tried to integrate BERT embeddings with recurrent layers like LSTM and GRU to benefit from transformers' algorithm, but it was eventually less effective than later approaches since it introduced unnecessary complexity.
Conclusion:
Transformer-based models such as BERT, RoBERTa, and ALBERT have demonstrated more accuracy than both deep learning models like LSTM and classic machine learning models like SVM and RF in a number of studies (Azizah et al., 2023)  (Nair et al., 2024). Frequently, hybrid models increase complexity without obvious advantages. Only slight or irregular benefits were obtained from attempts to integrate transformers with recurrent models (e.g., Nair et al. 2024, combining BERT with LSTM/GRU). This suggests that using sequential models not only make minimal contributions but also decrease efficiency. Graph-based techniques improve detection, but they come at a computational expense. According to Moorthy et al. (2025), graph neural networks (GNNs) can improve detection accuracy by modeling the links between users, content, and themes. However, the real-world implementation of dual-stream transformer–GNN model are limited because to their high computational costs. However, to achieve excellent results propagation patters are not always necessary. Patel & Sutrakar's (2025) success challenges the notion that modeling diffusion or spread is required by showing that GNNs may still produce good results when source tweets are the only input. As a result, looking at scalable, simpler pipelines without complete propagation data is a promising direction that can be explored for future forecasting tasks. It is very practical in the absence of additional information. Language, cultural context, and dataset bias remain the constrain. 
Models trained in English perform poorly in Indonesian environments, as noted by Azizah et al. (Azizah et al., 2023). Other challenges include possibility that models acquire biases from fact-checking datasets as well as majority of benchmarks in the field are English-centric. To conclude, transformer-based models are more powerful for misinformation detection techniques compared with traditional ML. GNNs improve results by modeling relationships, however additional complexity is not always leading to higher accuracy and there should be a balance between accuracy, efficiency, and practical deployability. Going forward the future research can concentrate on identifying viral posts and anticipating their impact in order to prevent (Dong et al., 2023)potential(Shu et al., 2017) harm(Horne & Adali, 2017).  

## Bibliography 
Akter, N., Abedin, M. Z., Tarafder, M. T. R., Nikita, N. A., Jahan, S. N., Rimi, N. N., & Islam, Md. T. (2025). Advanced Detection and Forecasting of Fake News on Social Media Platforms Using Natural Language Processing and Artificial Intelligence. Journal of Posthumanism, 5(6), 3208–3236. https://doi.org/10.63332/joph.v5i6.2446
Alammar, J. (2021). Ecco: An Open Source Library for the Explainability of Transformer Language Models. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations, 249–257. https://doi.org/10.18653/v1/2021.acl-demo.30
Azizah, S. F. N., Cahyono, H. D., Sihwi, S. W., & Widiarto, W. (2023). Performance Analysis of Transformer Based Models (BERT, ALBERT and RoBERTa) in Fake News Detection (Version 1). arXiv. https://doi.org/10.48550/ARXIV.2308.04950
Bahdanau, D., Chorowski, J., Serdyuk, D., Brakel, P., & Bengio, Y. (2016). End-to-end attention-based large vocabulary speech recognition. 2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 4945–4949. https://doi.org/10.1109/ICASSP.2016.7472618
Dong, L., Mohd Nor, N. H., Kai, G. B., Muhamad Adzmi, A., & Abdul Rais, S. S. (2023). Fake News Sharing Among Weibo Users in China. Jurnal Komunikasi: Malaysian Journal of Communication, 39(4), 284–305. https://doi.org/10.17576/JKMJC-2023-3904-15
Horne, B., & Adali, S. (2017). This Just In: Fake News Packs A Lot In Title, Uses Simpler, Repetitive Content in Text Body, More Similar To Satire Than Real News. Proceedings of the International AAAI Conference on Web and Social Media, 11(1), 759–766. https://doi.org/10.1609/icwsm.v11i1.14976
Islam, M. R., Liu, S., Wang, X., & Xu, G. (2020). Deep learning for misinformation detection on online social networks: A survey and new perspectives. Social Network Analysis and Mining, 10(1), 82. https://doi.org/10.1007/s13278-020-00696-x
Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., & Stoyanov, V. (2019). RoBERTa: A Robustly Optimized BERT Pretraining Approach (Version 1). arXiv. https://doi.org/10.48550/ARXIV.1907.11692
McCann, B., Bradbury, J., Xiong, C., & Socher, R. (2017). Learned in Translation: Contextualized Word Vectors (Version 2). arXiv. https://doi.org/10.48550/ARXIV.1708.00107
Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). Efficient Estimation of Word Representations in Vector Space (Version 3). arXiv. https://doi.org/10.48550/ARXIV.1301.3781
Nair, V., Pareek, Dr. J., & Bhatt, S. (2024). A Knowledge-Based Deep Learning Approach for Automatic Fake News Detection using BERT on Twitter. Procedia Computer Science, 235, 1870–1882. https://doi.org/10.1016/j.procs.2024.04.178
Patel, A., & Sutrakar, V. K. (2025). Advanced Text Analytics—Graph Neural Network for Fake News Detection in Social Media (Version 1). arXiv. https://doi.org/10.48550/ARXIV.2502.16157
Pennington, J., Socher, R., & Manning, C. (2014). Glove: Global Vectors for Word Representation. Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), 1532–1543. https://doi.org/10.3115/v1/D14-1162
Rama Moorthy, H., Avinash, N. J., Krishnaraj Rao, N. S., Raghunandan, K. R., Dodmane, R., Blum, J. J., & Gabralla, L. A. (2025). Dual stream graph augmented transformer model integrating BERT and GNNs for context aware fake news detection. Scientific Reports, 15(1), 25436. https://doi.org/10.1038/s41598-025-05586-w
Shu, K., Sliva, A., Wang, S., Tang, J., & Liu, H. (2017). Fake News Detection on Social Media: A Data Mining Perspective. ACM SIGKDD Explorations Newsletter, 19(1), 22–36. https://doi.org/10.1145/3137597.3137600
Twum, S. (2025). Misinformation Detection on Social Media, a Big Data and Machine Learning Approach. International Journal of Science, Architecture, Technology and Environment, 552–570. https://doi.org/10.63680/x2343vy86bt654v6
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., & Polosukhin, I. (2017). Attention Is All You Need. 31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA. https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf
Vosoughi, S., Roy, D., & Aral, S. (2018). The spread of true and false news online. Science, 359(6380), 1146–1151. https://doi.org/10.1126/science.aap9559
Wiessmann, J. (2024). Facebook and the Rohingya: A Case of Digital Complicity. Center for the Study of Organized Hate. https://www.csohate.org/2024/08/20/facebook-and-rohingya-a-case-of-digital-complicity/







