---
layout: post
title: Collaborative Discussion 1
subtitle: Initial Post
categories: discussion
tags: [discussion]
---
## Case study
For the first collaborative discussion I chose case study about Malicious Inputs to Content Filters. The full description can be found here https://www.acm.org/code-of-ethics/case-studies/malicious-inputs-to-content-filters. Here is a quick summary. 

The US Children’s Internet Protection Act (CIPA) mandates that public schools and libraries employ mechanisms to block inappropriate matter on the grounds that it is deemed harmful to minors. Blocker Plus is an automated Internet content filter designed to help these institutions comply with CIPA’s requirements. During a review session, the development team reviewed a number of complaints about content being blocked inappropriately.

My task was to compare the ACM analysis with the British Computer Science (BCS) code of conduct and here is my initial post. 

## Initial Post

For this assignment I chose Blocker case study which explains how ML algorithm malfunctioned and instead of protecting children from malicious content started blocking harmless content which could be useful for educational purposes. What we have here is that information about LGBTQ+ rights, vaccination, and climate science, which is useful to public discourse and for educational purposes was blocked along with dangerous for children content (Noble, 2018; Boyd & Crawford, 2012). The bias of the algorithm was cause by the actions of activist groups and resulted in censorship. The problem is that BCS Code of Conduct underlines that the rights and dignity of all people should be respected (BCS, 2023). The best way to address this is indeed a human oversight especially when the data that machine learning models ingests can be manipulated. I think such cases are unavoidable and it is important to learn from it and raise awareness. Another important point that BCS code of conduct makes is the significance of the IT and AI roles due to the high impact their job can have on society including public discourse. I like that UK champions this topic and ensures that automated decision are made by professionals in the public interest. I could not agree more with the idea of having a code of conduct for technology roles on the government level.

## Bibliography

Boyd, D., & Crawford, K. (2012). Critical questions for big data. Information, Communication & Society, 15(5), 662–679.
Noble, S. U. (2018). Algorithms of oppression: How search engines reinforce racism. NYU Press.
BCS. (2023). BCS Code of Conduct. British Computer Society. https://www.bcs.org/membership-and-registrations/become-a-member/bcs-code-of-conduct/

Then I responded to my peer Louis who chose Case study "Dark UX Patterns" which could be found here https://www.acm.org/code-of-ethics/case-studies/dark-ux-patterns. 
The change request Stewart received was simple: replace the website’s rounded rectangle buttons with arrows, and adjust the color palette to one that mixes red and green text. But he found the prototype confusing. He suggested to his manager that this design would probably trick users into more expensive options they didn’t want. The response was that these were the changes requested by the client.

## Initial post by Louis
Dark UX Patterns: An Ethical Analysis

The Dark UX Pattern ACM case study (Association for Computing Machinery, 2018a) presents an example in which a UX designer, Stewart, was instructed to implement interface designs that deliberately manipulated users into unintended actions by replacing clear buttons with confusing arrows and introducing colour schemes hostile to accessibility. The following analysis evaluates this situation in light of the ACM and BCS ethical codes.

Code Violations and Professional Standards

The design changes contravene fundamental principles within both the ACM Code and the BCS Code of Conduct. The BCS Code requires members to “have due regard for public health, privacy, security and wellbeing of others” and to “promote equal access to the benefits of IT” (British Computer Society, 2022). The deliberate obfuscation through arrow placement and the silent addition of warranties directly conflict with these obligations. Gray et al. (2018, p. 10) classify such practices as “forced action” patterns, where users “are required to perform a specific action to access (or continue accessing) a specific functionality.”

The ACM Code’s Principle 1.2 directs members to “avoid harm,” while Principle 1.4 requires fairness and non-discrimination, explicitly noting that technologies “should be as inclusive and accessible as possible” (Association for Computing Machinery, 2018b). The use of a red–green colour scheme that disadvantages visually impaired users is a direct breach of accessibility requirements. Both codes demand consideration of all stakeholders; however, the client celebrated increased revenue while disregarding accessibility complaints.

Legal and Social Implications

These practices raise serious concerns under accessibility guidelines and consumer protection legislation. Mathur et al. (2019, p. 17) document how dark patterns exploit cognitive biases including “anchoring, bandwagon and default effects,” disproportionately affecting vulnerable populations. Luguri and Strahilevitz (2021, p. 82) demonstrate experimentally that consumers exposed to dark patterns are “significantly more likely to remain enrolled in an unwanted service,” with participants of lower educational attainment being particularly susceptible. The accessibility violations potentially breach the Web Content Accessibility Guidelines (WCAG), which require perceivable information for all users.

Professional Responsibility

Stewart faced conflict between organisational pressure and professional duty. The BCS Code requires members to “avoid any inducement to unethical behaviour” and “not misrepresent or withhold information” (British Computer Society, 2022). Both Stewart and his manager failed to uphold these standards by proceeding with deceptive design implementations despite recognising their harmful nature.

## References

Association for Computing Machinery (2018a) Dark UX patterns, ACM Code of Ethics Case Studies. Available at: https://www.acm.org/code-of-ethics/case-studies/dark-ux-patterns [Accessed 16 August 2025].

Association for Computing Machinery (2018b) ACM Code of Ethics and Professional Conduct. Available at: https://www.acm.org/code-of-ethics [Accessed 16 August 2025].

British Computer Society (2022) BCS Code of Conduct. Available at: https://www.bcs.org/membership-and-registrations/become-a-member/bcs-code-of-conduct/ [Accessed 16 August 2025].

Gray, C.M., Kou, Y., Battles, B., Hoggatt, J. and Toombs, A.L. (2018) ‘The dark (patterns) side of UX design’, Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems, pp. 1–14 [Accessed 16 August 2025].

Luguri, J. and Strahilevitz, L.J. (2021) ‘Shining a light on dark patterns’, Journal of Legal Analysis, 13(1), pp. 43–109 [Accessed 16 August 2025].

Mathur, A., Acar, G., Friedman, M.J., Lucherini, E., Mayer, J., Chetty, M. and Narayanan, A. (2019) ‘Dark patterns at scale: findings from a crawl of 11K shopping websites’, Proceedings of the ACM on Human–Computer Interaction, 3(CSCW), pp. 1–32 [Accessed 16 August 2025].

## Peer response to Louis:

Hi Louis,
Thanks a lot for picking this study. When we got this assignment, I was so blown away by examples that I struggled with the choice. Thanks to you I have a chance to ponder on this case a bit more. If you think about it – intentional dark patterns are very common. When I go to the restaurant it is oftentimes the information about 10% tips that is written in such a small font that it is impossible to read. Thinking of Amazon being sued by Federal Trade Commission (FTC) for using “deceptive and manipulative tactics to trick users into enrolling in (prime membership)”  (“FTC v. Amazon: Prime Cancellation Case Goes to Trial Over Alleged ‘Dark Patterns,’” 2025). It is hard to believe that one of the most successful companies could engage in “Roach Motel” pattern (Gray et al., 2018) where it is easy to get into prime subscription and very difficult to get out of it.  Another notorious company for deceptive patterns use is Ryanair. Starting with concealing “opt out for travel insurance” forcing customers to purchase it, confusing text for opting out from subscription list, which is ticked by default, or “clicking continue triggering automatic consent” are just a few examples (Dark Patterns, n.d.) “Bait and Switch” is just one of the types of dark pattern that Ryanair uses (Gray et al., 2018). Both companies violate BCS principles of professional competence and integrity and public interest (“BCS Code of Conduct,” n.d.).
